import cv2
import numpy as np
import argparse

# -------------------------- 1. 16è‰²ç”Ÿæˆï¼ˆ4Ã—4ï¼‰ --------------------------
def create_color_texture_map():
    color_list = []
    # ç”Ÿæˆ16ç§é¢œè‰²ï¼ˆä»…æ‰§è¡Œä¸€æ¬¡ï¼‰
    for norm_x in range(4):
        for norm_y in range(4):
            r = 80 + norm_x * 30
            g = 80 + norm_y * 30
            b = 360 - r - g
            color_list.append((r, g, b))  # ä¿æŒ(R,G,B)é¡ºåº
    
    np.random.seed(432)
    texture_indices = np.random.randint(0, 13, size=len(color_list)).tolist()  # 16ä¸ªç´¢å¼•
    return color_list, texture_indices

# -------------------------- 2. çº¹ç†åŠ è½½ä¸åˆå§‹åŒ–é¢„å¤„ç†ï¼ˆæ ¸å¿ƒä¼˜åŒ–ï¼‰ --------------------------
def load_textures_and_preprocess(target_width, target_height, color_list, texture_indices, texture_dir="./texture"):
    """åˆå§‹åŒ–æ—¶ä¸€æ¬¡æ€§å®Œæˆæ‰€æœ‰é‡å¤æ“ä½œï¼šåŠ è½½çº¹ç†â†’è½¬æ¢æ•°ç»„â†’é¢„å¤„ç†æ˜ å°„å…³ç³»"""
    # 1. åŠ è½½çº¹ç†ï¼ˆä»…æ‰§è¡Œä¸€æ¬¡ï¼‰
    texture_paths = [f"{texture_dir}/{i}.png" for i in range(1, 14)]
    textures = []
    for path in texture_paths:
        tex = cv2.imread(path)
        if tex is None:
            raise FileNotFoundError(f"âŒ æ— æ³•åŠ è½½çº¹ç†å›¾ï¼š{path}")
        if tex.shape[0] != target_height or tex.shape[1] != target_width:
            tex = cv2.resize(tex, (target_width, target_height), interpolation=cv2.INTER_NEAREST)
        textures.append(tex)
    print(f"âœ… æˆåŠŸåŠ è½½{len(textures)}å¼ çº¹ç†å›¾")
    
    # 2. é¢„å¤„ç†ï¼šé¢œè‰²åˆ—è¡¨â†’æ•°ç»„ï¼ˆä»…æ‰§è¡Œä¸€æ¬¡ï¼‰
    color_array = np.array(color_list, dtype=np.uint8)[:, np.newaxis, np.newaxis, :]  # (16, 1, 1, 3)
    
    # 3. é¢„å¤„ç†ï¼šçº¹ç†åˆ—è¡¨â†’æ•°ç»„+ç´¢å¼•æ˜ å°„ï¼ˆä»…æ‰§è¡Œä¸€æ¬¡ï¼‰
    texture_array = np.array(textures, dtype=np.uint8)  # (13, H, W, 3)
    color_textures = texture_array[texture_indices]  # (16, H, W, 3)ï¼ˆé¢„è®¡ç®—16è‰²å¯¹åº”çš„çº¹ç†ï¼‰
    
    return color_array, color_textures  # è¿”å›é¢„å¤„ç†ç»“æœï¼Œä¾›åç»­å¸§ç›´æ¥ä½¿ç”¨

# -------------------------- 3. çº¹ç†è½¬æ¢ï¼ˆä»…å«é€å¸§å˜åŒ–çš„æ“ä½œï¼‰ --------------------------
def color_to_texture_frame(color_frame, color_array, color_textures):
    """ä»…å¤„ç†æ¯å¸§å˜åŒ–çš„éƒ¨åˆ†ï¼šç”Ÿæˆæ©ç â†’è®¡ç®—çº¹ç†åŒºåŸŸâ†’å åŠ """
    height, width = color_frame.shape[:2]
    
    # ç”Ÿæˆæ©ç ï¼ˆä»…éšå¸§å˜åŒ–ï¼‰
    all_masks = np.all(color_frame[np.newaxis, ...] == color_array, axis=3)  # (16, H, W)
    all_masks_uint8 = all_masks.astype(np.uint8) * 255
    all_masks_uint8 = all_masks_uint8[..., np.newaxis]  # (16, H, W, 1)
    
    # è®¡ç®—çº¹ç†åŒºåŸŸå¹¶å åŠ ï¼ˆå¤ç”¨åˆå§‹åŒ–çš„color_texturesï¼‰
    all_texture_regions = all_masks_uint8 * (255 - color_textures)
    texture_frame = np.sum(all_texture_regions, axis=0, dtype=np.uint16)
    return np.clip(texture_frame, 0, 255).astype(np.uint8)

# -------------------------- 4. è¾…åŠ©å‡½æ•° --------------------------
def get_contour_center(contour):
    M = cv2.moments(contour)
    if M["m00"] == 0:
        return (0, 0)
    cX = int(M["m10"] / M["m00"])
    cY = int(M["m01"] / M["m00"])
    return (cX, cY)

def get_position_based_color(center, frame_width, frame_height):
    total = 360
    norm_x = int(abs((center[0] * 2 / frame_width) - 1) * 4)
    norm_y = int(abs((center[1] * 2 / frame_height) - 1) * 4)
    norm_x = np.clip(norm_x, 0, 3)
    norm_y = np.clip(norm_y, 0, 3)
    
    r = 80 + norm_x * 30
    g = 80 + norm_y * 30
    b = 360 - r - g
    return (int(r), int(g), int(b))

# -------------------------- 5. ä¸»å‡½æ•°ï¼ˆåˆå§‹åŒ–ä¸é€å¸§å¤„ç†åˆ†ç¦»ï¼‰ --------------------------
def process_video(input_path, output_path, min_area=200):
    cap = cv2.VideoCapture(input_path)
    if not cap.isOpened():
        print(f"âŒ æ— æ³•æ‰“å¼€è§†é¢‘ï¼š{input_path}")
        return False

    # è§†é¢‘åŸºç¡€ä¿¡æ¯ï¼ˆä»…è·å–ä¸€æ¬¡ï¼‰
    frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
    frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
    fps = cap.get(cv2.CAP_PROP_FPS)
    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
    print(f"ğŸ“¹ è§†é¢‘ä¿¡æ¯ï¼šå®½={frame_width}, é«˜={frame_height}, å¸§ç‡={fps:.2f}, æ€»å¸§={total_frames}")

    # -------------------------- åˆå§‹åŒ–é˜¶æ®µï¼šæ‰€æœ‰é‡å¤æ“ä½œä»…æ‰§è¡Œä¸€æ¬¡ --------------------------
        # 1. ç”Ÿæˆé¢œè‰²åˆ—è¡¨å’Œçº¹ç†ç´¢å¼•ï¼ˆå›ºå®šä¸å˜ï¼‰
    color_list, texture_indices = create_color_texture_map()
    # 2. åŠ è½½çº¹ç†å¹¶é¢„å¤„ç†ï¼ˆé¢œè‰²æ•°ç»„ã€çº¹ç†æ˜ å°„ç­‰å›ºå®šæ“ä½œï¼‰
    color_array, color_textures = load_textures_and_preprocess(
        target_width=frame_width,
        target_height=frame_height,
        color_list=color_list,
        texture_indices=texture_indices
    )

    # è§†é¢‘å†™å…¥å™¨ï¼ˆä»…åˆå§‹åŒ–ä¸€æ¬¡ï¼‰
    fourcc = cv2.VideoWriter_fourcc(*'mp4v')
    out = cv2.VideoWriter(output_path, fourcc, fps, (frame_width, frame_height))
    if not out.isOpened():
        print(f"âŒ æ— æ³•åˆ›å»ºè¾“å‡ºè§†é¢‘ï¼š{output_path}")
        cap.release()
        return False

    # è¾¹ç¼˜æ£€æµ‹å·¥å…·ï¼ˆä»…åˆå§‹åŒ–ä¸€æ¬¡ï¼‰
    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))
    kernel = np.ones((3, 3), np.uint8)
    frame_count = 0

    # -------------------------- é€å¸§å¤„ç†ï¼šä»…æ‰§è¡Œå˜åŒ–çš„æ“ä½œ --------------------------
    while cap.isOpened():
        ret, frame = cap.read()
        if not ret:
            break

        frame_count += 1
        if frame_count % 5 == 0 or frame_count == total_frames:
            progress = (frame_count / total_frames) * 100
            print(f"ğŸ”„ è¿›åº¦ï¼š{frame_count}/{total_frames} å¸§ ({progress:.1f}%)")

        # è¾¹ç¼˜æ£€æµ‹ï¼ˆé€å¸§å˜åŒ–ï¼‰
        #'''
        frame = cv2.GaussianBlur(frame, (5, 5), 0)
        img_f = frame.astype(np.float32)
        sobel_x = cv2.Sobel(img_f, cv2.CV_32F, 1, 0, ksize=3)
        sobel_y = cv2.Sobel(img_f, cv2.CV_32F, 0, 1, ksize=3)
        sobel_x_sq = cv2.multiply(sobel_x, sobel_x)
        sobel_y_sq = cv2.multiply(sobel_y, sobel_y)
        sobel_mag = cv2.sqrt(sobel_x_sq + sobel_y_sq)
        gray_mag = np.max(sobel_mag, axis=2)
        gray_mag = cv2.GaussianBlur(gray_mag, (5, 5), 0)
        gray_mag = np.clip(gray_mag, 0, 255)
        _, edges = cv2.threshold(gray_mag.astype(np.uint8), 20, 255, cv2.THRESH_BINARY)
        edges = cv2.dilate(edges, kernel, iterations=1)
        edges = cv2.erode(edges, kernel, iterations=1)
        #output_frame = cv2.cvtColor(edges, cv2.COLOR_GRAY2BGR)
        #out.write(output_frame)
        '''
        hsv_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)
        s_channel = hsv_frame[:, :, 1]
        v_channel = hsv_frame[:, :, 2]

        s_enhanced = clahe.apply(s_channel)
        s_blurred = cv2.GaussianBlur(s_enhanced, (5, 5), 0)
        s_edges = cv2.Canny(s_blurred, threshold1=3, threshold2=80)

        v_enhanced = clahe.apply(v_channel)
        v_blurred = cv2.GaussianBlur(v_enhanced, (5, 5), 0)
        v_edges = cv2.Canny(v_blurred, threshold1=3, threshold2=80)

        merged_edges = cv2.bitwise_or(s_edges, v_edges)
        merged_edges = cv2.dilate(merged_edges, kernel, iterations=1)
        merged_edges = cv2.erode(merged_edges, kernel, iterations=1)

        edges = merged_edges
        #'''
        # æŸ“è‰²ï¼ˆé€å¸§å˜åŒ–ï¼‰
        color_canvas = np.zeros((frame_height, frame_width, 3), dtype=np.uint8)
        contours, hierarchy = cv2.findContours(edges, cv2.RETR_CCOMP, cv2.CHAIN_APPROX_SIMPLE)
        for i in range(len(contours)):
            contour = contours[i]
            area = cv2.contourArea(contour)
            if area < min_area:
                continue
            contour_hierarchy = hierarchy[0][i] if hierarchy is not None else [0, 0, 0, -1]
            is_outer = (contour_hierarchy[3] == -1)
            is_inner = (contour_hierarchy[3] != -1) and (contour_hierarchy[2] == -1)
            if not (is_outer or is_inner):
                continue
            center = get_contour_center(contour)
            block_color = get_position_based_color(center, frame_width, frame_height)
            cv2.drawContours(color_canvas, [contour], -1, block_color, thickness=-1)
            cv2.drawContours(color_canvas, [contour], -1, block_color, thickness=2)

        output_frame = color_canvas

        # çº¹ç†è½¬æ¢
        final_texture_frame = color_to_texture_frame(output_frame, color_array, color_textures)
        out.write(final_texture_frame)
        #'''
    # é‡Šæ”¾èµ„æº
    cap.release()
    out.release()
    cv2.destroyAllWindows()
    print(f"ğŸ‰ å¤„ç†å®Œæˆï¼è¾“å‡ºæ–‡ä»¶ï¼š{output_path}")
    return True

if __name__ == "__main__":
    parser = argparse.ArgumentParser(description="åˆå§‹åŒ–ä¼˜åŒ–çš„çº¹ç†è§†é¢‘ç”Ÿæˆå™¨")
    parser.add_argument('--input', type=str, default="./input/hs3.mp4", help='è¾“å…¥è§†é¢‘è·¯å¾„')
    parser.add_argument('--output', type=str, default="./output/hs3.mp4", help='è¾“å‡ºçº¹ç†è§†é¢‘è·¯å¾„')
    parser.add_argument('--min-area', type=int, default=150, help="æœ€å°æŸ“è‰²åŒºåŸŸé¢ç§¯")
    args = parser.parse_args()
    process_video(args.input, args.output, args.min_area)
